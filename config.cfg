#///    \file
#///    CONFIG_CFG
#///
#///    \Author: Ayesha Afzal <ayesha.afzal@fau.de>
#///    \Copyright Â© 2024 HPC, FAU Erlangen-Nuremberg. All rights reserved.
#///

# APPLICATION MODEL
benchmark_kernel = STREAM     	     # name of the kernel used in the program
kernel_mode = FILE                   # mode of the kernel (FILE, SRC, LBL, COMP)


# CLUSTER MODEL: Resource allocation, intercluster characteristics, and runtime modalities
heteregeneous = 0                    # a bool flag to enable or disable the second system (1: enabled, 0: disabled)
number_of_iterations = 500           # number of iterations of the program
## first system
dim_x = 1000000000                   # problem size for first system; high-dimensional parameters will be disregarded for low-dimensional problems.
dim_y = 20000
dim_z = 0
task_per_node = 18                   # number of running processes on one node of the first system
number_of_processes = 72             # total number of running processes on the first system
## second system
secondary_dim_x = 1000000000         # problem size for second system; high-dimensional parameters will be disregarded for low-dimensional problems.
secondary_dim_y = 20000
secondary_dim_z = 0
secondary_task_per_node = 36         # number of running processes on one node of the second system
secondary_number_of_processes = 36   # total number of running processes on the second system


# INTERCONNECT MODEL
## first system
interconnect = InfiniBand	     # name of the interconnect for the first system (InfiniBand, OmniPath, Tofu-D)
MPI_library = IntelMPI               # name of the MPI library for the first system (IntelMPI, WaitIO)
comm_model = 0                       # performance model of communication for the first system (0: LogGP, 1: HOCKNEY)
waitio_mode = socket                 # mode of the WaitIO MPI library for the first system (socket, file or hybrid)
## second system
secondary_interconnect = InfiniBand  # name of the interconnect for the second system (InfiniBand, OmniPath, Tofu-D)
secondary_MPI_library = IntelMPI     # name of the MPI library for the second system (IntelMPI, WaitIO)
secondary_comm_model = 0             # performance model of communication for the second system (0: LogGP, 1: HOCKNEY)
secondary_waitio_mode = socket       # mode of the WaitIO MPI library for the second system (socket, file or hybrid)

# NODE MODEL
## first system
micro_architecture = IcelakeSP_Platinum-8360Y 		# name of the YAML machine file for the first system 
FP_instructions_per_cycle = 4         			# Floating Point instructions per cycle for the first system's processor
compiler-flags = -03                     		# STD and SIMD optimizations for the first system (-03 -xCORE-AVX512 -qopt-zmm-usage=high, -03 -xHost -xAVX, -Kfast -DTOFU); If not set, flags are taken from the YAML formatted machine file.
pmodel = ECM                          			# performance model of computation for the first system (ECM, Roofline)
vvv = 0                               		        # a bool flag to enable or disable the verbose node output for the first system (0: disabled, 1: enabled)
cache-predictor = LC                  			# cache prediction with layer conditions or cache simulation with pycachesim for the first system (LC, SIM)
penalty = 0                           			# runtime penalty for the computation model in nanoseconds for the first system, used only in LBL or COMP mode
## second system
secondary_micro_architecture = IcelakeSP_Platinum-8360Y # name of the YAML machine file for the second system 
secondary_FP_instructions_per_cycle = 4                 # Floating Point instructions per cycle for the second system's processor
secondary_compiler_flags = -03                        	# STD and SIMD optimizations for the second system (-03 -xCORE-AVX512 -qopt-zmm-usage=high, -03 -xHost -xAVX, -Kfast -DTOFU); If not set, flags are taken from the YAML formatted machine file.
secondary_pmodel = ECM                                  # performance model of computation for the second system (ECM, Roofline)
decondary_vvv = 0                                       # a bool flag to enable or disable the verbose node output for the second system (0: disabled, 1: enabled)
secondary_cache_predictor = LC                          # cache prediction with layer conditions or ache simulation with pycachesim for the second system (LC, SIM)
secondary_penalty = 0                                   # penalty for the computation model in nanoseconds for the second system, used only in LBL or COMP mode
# Roofline model parameters
FLOPs_per_iteration = 2               # number of flops in one iteration
R_streams = 3                         # number of read streams
W_streams = 1                         # number of write streams
datasize_in_GB = 2.98                 # number of array elements * (R_streams + W_streams) * size of datatype


# DELAY INJECTION MODE
delay = 0                             # a bool flag to enable or disable the delay injection (0: disabled, 1: enabled)
delay_intensity = 20                  # intensity of delay as a multiple of computation time of one iteration                                 
delay_rank = 4                        # process rank of the injected delay
delay_timestep = 5                    # iteration for the occurrence of the injected delay

# NOISE INJECTION MODE
noise = 0                             # a bool flag to enable or disable the noise injection (0: disabled, 1: enabled)
noise_intensity = 5000                # intensity of random noise, i.e., rand() % noise_intensity                                
noise_start_timestep = 1              # starting iteration for the injected noise
noise_stop_timestep = 50              # ending iteration for the injected noise


# OUTPUT
filename = DisCostiC.csv	      # output file name that contains details for the debug purpose
vizfilename = DisCostiC		      # output file name that contains all time-rank tracing data for visualization with Drawviz tool
chromevizfilename = DisCostiC	      # output file name that contains all time-rank tracing data for visualization with Chrome tracing browser
Verbose = 0			      # a bool flag to enable or disable the verbose output (0: disabled, 1: enabled)
batchmode = 0			      # a bool flag to enable or disable the batch mode (0: disable, i.e., printing performance for each rank, 1: enabled, i.e., never print detailed all rank info)
timeunit_conv = 1		      # a time multiplier for conversation from baseline unit of nanoseconds to some other unit
